{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/root/.cache/huggingface/datasets': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm -r ~/.cache/huggingface/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 55\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Features, Value, Sequence\n",
    "from transformers import (\n",
    "    MarkupLMForTokenClassification,\n",
    "    MarkupLMProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# Параметры модели и пути\n",
    "MODEL_NAME = \"microsoft/markuplm-base\"  # или \"microsoft/markuplm-large\"\n",
    "LABEL_MAP_PATH = \"label_map.json\"\n",
    "DATA_DIR = \"dataset/markuplm_dataset_finetuning/\"\n",
    "MODEL_SAVE_PATH = \"models\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 3e-5\n",
    "SEED = 42\n",
    "\n",
    "# Загрузка label map\n",
    "with open(LABEL_MAP_PATH) as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "# Преобразуем id2label, ключи делаем int\n",
    "id2label = {int(k): v for k, v in label_map[\"id2label\"].items()}\n",
    "label2id = label_map[\"label2id\"]\n",
    "num_labels = len(id2label)\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "\n",
    "# Задаём expected_fields — список всех возможных полей (если потребуется)\n",
    "expected_fields = ['title', 'author', 'date', 'doi', 'issn', 'eissn', 'journal',\n",
    "                   'publisher', 'pages', 'first_page', 'last_page', 'language', 'volume',\n",
    "                   'issue', 'abstract', 'affiliation', 'keyword', 'doc_type', 'isbn',\n",
    "                   'eisbn', 'editor', 'orcid', 'book_version', 'subtitle', 'conference_title',\n",
    "                   'book_series', 'book_title']\n",
    "\n",
    "features = Features({\n",
    "    \"id\": Value(\"string\"),\n",
    "    \"source_file\": Value(\"string\"),\n",
    "    \"resource\": Value(\"string\"),\n",
    "    \"doc_type\": Value(\"string\"),\n",
    "    \"html\": Value(\"string\"),\n",
    "    \"tokens\": Sequence(Value(\"string\")),\n",
    "    \"xpaths\": Sequence(Value(\"string\")),\n",
    "    \"metadata\": Features({\n",
    "        field: Features({\n",
    "            \"text\": Sequence(Value(\"string\")),\n",
    "            \"xpaths\": Sequence(Value(\"string\"))\n",
    "        }) for field in expected_fields\n",
    "    }),\n",
    "    \"node_labels\": Sequence(Value(\"int64\")),\n",
    "    \"processing_time\": Value(\"string\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b496cbd72754ea2932713f25e73508f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загружаем датасет в режиме streaming\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\n",
    "        \"train\": f\"{DATA_DIR}/train/*.parquet\",\n",
    "        \"validation\": f\"{DATA_DIR}/val/*.parquet\",\n",
    "        \"test\": f\"{DATA_DIR}/test/*.parquet\"\n",
    "    },\n",
    "    features=features,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# Применяем shuffle с буфером для каждой части.\n",
    "# Размер буфера можно изменять в зависимости от объёма и доступной памяти.\n",
    "train_dataset = dataset[\"train\"].shuffle(buffer_size=10000, seed=SEED)\n",
    "validation_dataset = dataset[\"validation\"].shuffle(buffer_size=5000, seed=SEED)\n",
    "test_dataset = dataset[\"test\"].shuffle(buffer_size=5000, seed=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.take(30000)  # Ограничение для теста\n",
    "validation_dataset = validation_dataset.take(3000)\n",
    "test_dataset = test_dataset.take(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MarkupLMProcessor.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    parse_html=False,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "processor.parse_html = False\n",
    "\n",
    "#def split_into_chunks(nodes, xpaths, labels, max_length):\n",
    "#    chunks = []\n",
    "#    start = 0\n",
    "#    n = len(nodes)\n",
    "#    \n",
    "#    while start < n:\n",
    "#        # Определяем конец чанка\n",
    "#        end = start + max_length\n",
    "#        # Ищем последнюю значимую метку в текущем диапазоне\n",
    "#        last_sig_in_chunk = -1\n",
    "#        for i in range(start, min(end, n)):\n",
    "#            if labels[i] != 0:\n",
    "#                last_sig_in_chunk = i\n",
    "#                \n",
    "#        # Если есть значимые метки, корректируем конец\n",
    "#        if last_sig_in_chunk != -1:\n",
    "#            end = last_sig_in_chunk + 1  # Включаем последнюю значимую метку\n",
    "#        else:\n",
    "#            end = min(end, n)  # Просто обрезаем до max_length\n",
    "#            \n",
    "#        # Добавляем чанк\n",
    "#        chunks.append({\n",
    "#            \"nodes\": nodes[start:end],\n",
    "#            \"xpaths\": xpaths[start:end],\n",
    "#            \"labels\": labels[start:end]\n",
    "#        })\n",
    "#        \n",
    "#        start = end  # Переходим к следующему чанку\n",
    "#        \n",
    "#    return chunks\n",
    "\n",
    "def split_into_chunks(nodes, xpaths, labels, max_length):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(nodes)\n",
    "    \n",
    "    while start < n:\n",
    "        end = start + max_length\n",
    "        # Упрощенная логика без поиска меток\n",
    "        chunks.append({\n",
    "            \"nodes\": nodes[start:end],\n",
    "            \"xpaths\": xpaths[start:end],\n",
    "            \"labels\": labels[start:end]\n",
    "        })\n",
    "        start = end\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "def process_examples(examples):\n",
    "    all_nodes = []\n",
    "    all_xpaths = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Обрабатываем каждый пример в батче\n",
    "    for i in range(len(examples[\"tokens\"])):\n",
    "        nodes = examples[\"tokens\"][i]\n",
    "        xpaths = examples[\"xpaths\"][i]\n",
    "        labels = examples[\"node_labels\"][i]\n",
    "        \n",
    "        # Разбиваем на чанки\n",
    "        chunks = split_into_chunks(nodes, xpaths, labels, MAX_LENGTH)\n",
    "        \n",
    "        # Собираем все чанки\n",
    "        for chunk in chunks:\n",
    "            all_nodes.append(chunk[\"nodes\"])\n",
    "            all_xpaths.append(chunk[\"xpaths\"])\n",
    "            all_labels.append(chunk[\"labels\"])\n",
    "    \n",
    "    # Обрабатываем все чанки через процессор\n",
    "    processed = processor(\n",
    "        nodes=all_nodes,\n",
    "        xpaths=all_xpaths,\n",
    "        node_labels=all_labels,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    # Маскируем метки для padding токенов\n",
    "    labels = processed[\"labels\"]\n",
    "    labels[processed[\"attention_mask\"] == 0] = -100\n",
    "    processed[\"labels\"] = labels\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return processed\n",
    "\n",
    "# Обрабатываем датасеты. При streaming датасетах метод .map возвращает IterableDataset.\n",
    "train_dataset = train_dataset.map(\n",
    "    process_examples,\n",
    "    batched=True,\n",
    "    remove_columns=list(dataset[\"train\"].features.keys())\n",
    ")\n",
    "validation_dataset = validation_dataset.map(\n",
    "    process_examples,\n",
    "    batched=True,\n",
    "    remove_columns=list(dataset[\"validation\"].features.keys())\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    process_examples,\n",
    "    batched=True,\n",
    "    remove_columns=list(dataset[\"test\"].features.keys())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarkupLMForTokenClassification were not initialized from the model checkpoint at microsoft/markuplm-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загружаем метрику seqeval для оценки\n",
    "seqeval = load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(\n",
    "        predictions=true_predictions,\n",
    "        references=true_labels,\n",
    "        mode=\"strict\",\n",
    "        scheme=\"IOB2\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Загружаем модель MarkupLM для задачи токенной классификации\n",
    "model = MarkupLMForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True  # если размеры эмбеддингов не совпадают\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",        # Переключаем на оценку по шагам\n",
    "    save_strategy=\"steps\",        # Сохранение по шагам\n",
    "    eval_steps=3000,  # Оценка после каждой эпохи\n",
    "    save_steps=6000,   # Сохранение после каждой эпохи\n",
    "    logging_steps=3000,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    "    max_steps=40000, #~112500 if we gonna use full dataset\n",
    "    #use_cpu=True # for debug\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40000' max='40000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40000/40000 4:15:21, Epoch 1/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>0.370523</td>\n",
       "      <td>0.539863</td>\n",
       "      <td>0.167113</td>\n",
       "      <td>0.255223</td>\n",
       "      <td>0.959662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.372104</td>\n",
       "      <td>0.645291</td>\n",
       "      <td>0.488308</td>\n",
       "      <td>0.555930</td>\n",
       "      <td>0.963226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.357707</td>\n",
       "      <td>0.648391</td>\n",
       "      <td>0.421943</td>\n",
       "      <td>0.511213</td>\n",
       "      <td>0.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.314948</td>\n",
       "      <td>0.719739</td>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.670387</td>\n",
       "      <td>0.971675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.230355</td>\n",
       "      <td>0.655815</td>\n",
       "      <td>0.710371</td>\n",
       "      <td>0.682004</td>\n",
       "      <td>0.975811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.296451</td>\n",
       "      <td>0.806095</td>\n",
       "      <td>0.657639</td>\n",
       "      <td>0.724339</td>\n",
       "      <td>0.979226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.259310</td>\n",
       "      <td>0.800873</td>\n",
       "      <td>0.771744</td>\n",
       "      <td>0.786039</td>\n",
       "      <td>0.981718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.805935</td>\n",
       "      <td>0.980440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.260588</td>\n",
       "      <td>0.873862</td>\n",
       "      <td>0.745032</td>\n",
       "      <td>0.804321</td>\n",
       "      <td>0.981101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.268272</td>\n",
       "      <td>0.781554</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.793942</td>\n",
       "      <td>0.980203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.275011</td>\n",
       "      <td>0.877041</td>\n",
       "      <td>0.762131</td>\n",
       "      <td>0.815558</td>\n",
       "      <td>0.981400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.213618</td>\n",
       "      <td>0.823611</td>\n",
       "      <td>0.797994</td>\n",
       "      <td>0.810600</td>\n",
       "      <td>0.982253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>0.838557</td>\n",
       "      <td>0.801276</td>\n",
       "      <td>0.819492</td>\n",
       "      <td>0.982193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Запуск обучения\n",
    "trainer.train()\n",
    "\n",
    "# Сохраняем модель и processor\n",
    "output_dir = \"./fine_tuned_markuplm_base\"\n",
    "trainer.save_model(output_dir)\n",
    "processor.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "Precision: 0.8617\n",
      "Recall: 0.7479\n",
      "F1 Score: 0.8008\n",
      "Accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(\"Test results:\")\n",
    "print(f\"Precision: {results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {results['eval_recall']:.4f}\")\n",
    "print(f\"F1 Score: {results['eval_f1']:.4f}\")\n",
    "print(f\"Accuracy: {results['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
